Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
100000,-0.49497023,2.1182103,2.1203768,0.06523181,0.00029942402,4999.0,0.0,0.0,1.0
110000,-0.727378,2.1335776,15.431272,0.068239026,0.0002993693,None,-790.0,-790.0,1.0
120000,-0.8610468,2.085058,2.5107322,0.0722946,0.00029931555,None,None,None,1.0
130000,-1.1051471,2.0239496,4.230493,0.073256925,0.00029925408,None,None,None,1.0
140000,-0.79888546,1.9522432,1.748322,0.065852076,0.00029919264,None,None,None,1.0
150000,-0.92799205,1.988909,2.2366948,0.06668687,0.00029913182,2283.0,0.0,0.0,1.0
160000,-0.8114007,1.9079411,1.1537676,0.07201255,0.000299071,None,None,None,1.0
170000,-0.44271693,1.9540008,1.3821496,0.07125036,0.00029900952,None,None,None,1.0
180000,-0.78657776,1.9608054,2.0235236,0.06842165,0.00029894424,None,None,None,1.0
190000,-0.89946455,1.8839222,0.94899184,0.061982483,0.0002988905,None,None,None,1.0
