Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
60000,-8.70092,0.905261,120.67533,0.06642591,0.00029967033,4999.0,-1851.960262169892,-1851.960262169892,1.0
70000,-10.798755,0.54503375,79.10134,0.06755977,0.00029960665,None,None,None,1.0
80000,-13.921816,1.2113038,77.47321,0.06444803,0.0002995496,None,None,None,1.0
90000,-13.908447,1.2995863,67.99934,0.072542354,0.00029949262,None,None,None,1.0
100000,-14.532494,0.88988554,47.324432,0.07273503,0.00029942926,None,None,None,1.0
110000,-16.436405,0.80696774,45.67254,0.065728195,0.0002993659,4999.0,-1336.8457041814922,-1336.8457041814922,1.0
120000,-9.745739,0.4785344,147.82875,0.068706185,0.00029930833,None,-2924.928022429347,-2924.928022429347,1.0
130000,-12.341435,1.1389707,60.847973,0.071063645,0.00029925132,None,None,None,1.0
