Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,2.1779106,-0.036201928,3.409101,0.06554875,0.0002999685,4999.0,-10.0,-10.0,1.0
20000,2.1764295,-0.6284194,7.8461595,0.06836237,0.00029991212,4999.0,-398.5,-398.5,1.0
30000,1.9963938,-1.4991415,1.8576437,0.068923876,0.0002998495,4999.0,-167.0,-167.0,1.0
40000,1.6092666,-1.4136013,1.732301,0.07185416,0.00029978677,4999.0,14.0,14.0,1.0
50000,1.564255,-0.90328383,3.5660737,0.065979436,0.00029973043,4999.0,-7.5,-7.5,1.0
60000,1.441748,-0.63176477,1.8809332,0.071136236,0.00029967402,4999.0,-5.5,-5.5,1.0
70000,1.3615811,-0.5517959,14.996408,0.062630035,0.00029961136,4999.0,52.0,52.0,1.0
80000,1.4329921,-0.22929978,8.597329,0.06729164,0.0002995487,4999.0,109.0,109.0,1.0
90000,1.4573106,-0.061580416,13.227549,0.07206676,0.00029948604,4999.0,71.0,71.0,1.0
100000,1.4308641,-0.12271007,15.192289,0.063481025,0.00029942967,4999.0,109.0,109.0,1.0
110000,1.4320028,0.04141992,25.679026,0.07010681,0.0002993733,4999.0,137.5,137.5,1.0
120000,1.4390476,0.31004584,13.972684,0.06426993,0.00029931057,4999.0,132.0,132.0,1.0
130000,1.3535997,0.8441064,19.971592,0.069023415,0.00029924797,4999.0,159.5,159.5,1.0
140000,1.3305744,0.5718212,16.035769,0.071744144,0.00029918525,4999.0,180.5,180.5,1.0
150000,1.1701823,-0.03749,26.214617,0.068056114,0.00029912888,4999.0,46.5,46.5,1.0
160000,1.1489762,-0.0012927599,29.236588,0.06711657,0.0002990725,4999.0,147.0,147.0,1.0
170000,1.0757443,-0.004641931,38.658928,0.06781489,0.0002990099,4999.0,205.5,205.5,1.0
180000,1.266719,0.17461501,26.48615,0.06815256,0.00029894718,4999.0,236.0,236.0,1.0
190000,1.2089036,-0.06159179,49.335358,0.061005123,0.00029889084,4999.0,152.0,152.0,1.0
200000,1.18741,0.75935245,35.97464,0.073383555,0.0002988344,4999.0,270.5,270.5,1.0
