Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
60000,-1.3869872,1.4363331,38.644096,0.074589774,0.00029967033,4999.0,31.316668618809093,31.316668618809093,1.0
70000,-2.542416,0.6874945,80.99101,0.0648427,0.00029960665,None,None,None,1.0
80000,-3.193244,0.885684,3.707243,0.06377507,0.0002995496,None,None,None,1.0
90000,-3.344721,0.8552638,8.618333,0.06798894,0.00029949262,None,None,None,1.0
100000,-3.542332,0.8563366,31.788635,0.06598292,0.00029942926,None,None,None,1.0
110000,-2.7270586,0.7800879,9.109915,0.07090525,0.0002993659,4999.0,286.19116343706844,286.19116343706844,1.0
120000,1.1009617,1.50839,40.201553,0.066529974,0.00029930833,None,-14.981461852788925,-14.981461852788925,1.0
130000,-0.018437605,0.9503378,54.969673,0.07208545,0.00029925132,None,None,None,1.0
140000,-2.104268,1.1734017,11.546865,0.064506605,0.00029918793,None,None,None,1.0
150000,-3.8015113,1.2742414,33.269154,0.073271334,0.00029913094,None,None,None,1.0
160000,-3.5965817,1.2584085,23.349031,0.064915314,0.0002990739,None,None,None,1.0
170000,-1.0222558,1.1333181,70.720505,0.06965569,0.00029901034,4999.0,104.57256911288609,104.57256911288609,1.0
180000,0.8505455,0.64804006,51.478535,0.06229477,0.00029894663,None,None,None,1.0
190000,0.40283662,0.85173965,38.818504,0.07277683,0.00029888964,None,None,None,1.0
200000,-0.17653011,1.065915,19.648775,0.06556015,0.0002988326,None,None,None,1.0
210000,-1.1184106,1.1987236,41.77736,0.06557836,0.00029876924,None,None,None,1.0
220000,-1.8528198,1.1966615,22.696033,0.06558667,0.00029870588,4999.0,-34.774081103503704,-34.774081103503704,1.0
230000,1.569861,0.9889285,122.05725,0.0658403,0.00029864832,None,540.6603561490774,540.6603561490774,1.0
240000,0.93553877,0.8931927,26.201962,0.06547289,0.00029859133,None,None,None,1.0
250000,-0.34903896,1.1715088,12.358965,0.063754275,0.00029852794,None,None,None,1.0
