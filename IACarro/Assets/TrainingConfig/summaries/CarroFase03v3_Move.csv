Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,0.48566866,95.113106,4750.951,0.07279303,0.0002999684,2999.0,5475.09282430013,5475.09282430013,1.0
20000,0.5040661,94.42791,4162.3037,0.06758125,0.00029991154,2999.0,5714.133179982503,5714.133179982503,1.0
30000,0.4814065,95.722855,4553.284,0.065533355,0.00029984833,2999.0,5414.172676086426,5414.172676086426,1.0
40000,0.52021146,93.39347,3676.0898,0.06582354,0.00029979146,2999.0,4021.401587128639,4021.401587128639,1.0
50000,0.54727226,99.88532,5822.13,0.06390298,0.0002997346,2999.0,5960.757852355639,5960.757852355639,1.0
60000,0.532735,100.0055,4792.492,0.07139685,0.00029967137,2999.0,5593.811930338542,5593.811930338542,1.0
70000,0.496773,102.1648,5995.6816,0.07033644,0.00029960822,2999.0,6029.9251474142075,6029.9251474142075,1.0
80000,0.5091243,103.20699,4918.594,0.07238187,0.0002995513,2999.0,5756.032440503438,5756.032440503438,1.0
90000,0.5361792,104.84241,4700.0474,0.069844335,0.00029949445,2999.0,5615.959511915843,5615.959511915843,1.0
100000,0.5817483,105.268585,4800.5405,0.0717755,0.00029943127,2999.0,5612.595812320709,5612.595812320709,1.0
110000,0.62176156,105.79474,4717.693,0.076810434,0.00029936808,2999.0,5408.153829564651,5408.153829564651,1.0
120000,0.5673157,106.15309,4254.0005,0.06813938,0.0002993112,2999.0,5435.629189809163,5435.629189809163,1.0
130000,0.55848956,106.53403,4511.311,0.06891105,0.00029925435,2999.0,5667.582590341568,5667.582590341568,1.0
