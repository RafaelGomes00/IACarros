Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
30000,-1.0490425,1.6231327,68.42339,0.07103382,0.0002998471,1999.0,-299.3609930967743,-299.3609930967743,1.0
40000,-0.76193726,1.8878648,167.64754,0.060215916,0.00029978988,None,None,None,1.0
50000,-1.7749877,1.8133734,60.68153,0.069017574,0.00029973223,1999.0,-461.25255063921213,-461.25255063921213,1.0
60000,-1.7924175,1.7847847,141.78275,0.068615064,0.00029966843,None,None,None,1.0
70000,-1.4489807,2.0203211,70.94733,0.064802594,0.00029961113,1999.0,-380.8135620193048,-380.8135620193048,1.0
80000,-4.9591966,1.4607832,103.09729,0.06591109,0.00029955333,None,None,None,1.0
90000,-2.8427272,1.755827,80.73983,0.070233084,0.00029948974,1999.0,-481.94531686604023,-481.94531686604023,1.0
100000,-3.2196023,1.7101569,52.78261,0.0698398,0.00029942556,None,None,None,1.0
110000,0.38494295,1.7753073,65.762375,0.06340264,0.00029936855,1999.0,-23.423254466801883,-23.423254466801883,1.0
120000,-2.2795398,1.743405,49.69034,0.06855364,0.00029931046,None,50.22806894034147,50.22806894034147,1.0
130000,0.69832075,1.7840463,137.7825,0.069689386,0.00029924707,None,None,None,1.0
140000,-0.23176111,1.51425,128.81012,0.06632065,0.0002991893,1999.0,-162.51137819818476,-162.51137819818476,1.0
150000,4.1872683,1.8106164,132.27567,0.06870144,0.00029913196,None,None,None,1.0
160000,1.9141673,1.5607365,76.22147,0.067229465,0.000299068,1999.0,333.2685278342529,333.2685278342529,1.0
