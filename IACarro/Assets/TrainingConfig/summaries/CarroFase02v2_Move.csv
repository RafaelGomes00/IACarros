Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,2.0746043,0.14562024,0.15692912,0.05609028,0.0002999685,4999.0,-10.0,-10.0,1.0
20000,1.8947014,0.5054082,0.72983575,0.060207445,0.00029991212,4999.0,5.0,5.0,1.0
30000,1.7310449,0.23646063,1.2468996,0.06241112,0.0002998495,4999.0,-14.5,-14.5,1.0
40000,1.6480659,0.078015015,1.397022,0.065133154,0.00029978677,4241.0,0.6666666666666666,0.6666666666666666,1.0
50000,1.4540395,-0.14191876,2.0108645,0.06060479,0.00029973054,3659.0,5.333333333333333,5.333333333333333,1.0
60000,1.3041146,0.047439136,1.2340639,0.05977751,0.00029967423,2976.0,3.0,3.0,1.0
70000,1.4655228,0.24292248,1.7281071,0.06310667,0.00029961154,4999.0,5.5,5.5,1.0
80000,1.7662374,0.30295968,2.0671802,0.06365847,0.00029954885,4999.0,-2.0,-2.0,1.0
90000,1.8979828,-0.000650925,1.6499679,0.06418769,0.0002994862,4999.0,-46.0,-46.0,1.0
100000,1.9848359,-0.10421195,3.944808,0.07206485,0.00029942984,4999.0,-32.0,-32.0,1.0
110000,1.924637,0.16942446,1.2141472,0.06588305,0.00029937335,4999.0,-30.5,-30.5,1.0
120000,1.7117056,0.26858157,2.3300638,0.06359091,0.00029931078,4999.0,17.5,17.5,1.0
