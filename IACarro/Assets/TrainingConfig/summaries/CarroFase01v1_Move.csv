Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
30000,2.1790807,-0.09847494,13.195742,0.07288703,0.0002998471,1999.0,-14.938012108884074,-14.938012108884074,1.0
40000,2.1520922,-0.27777672,267.07028,0.06825735,0.00029978988,None,None,None,1.0
50000,2.0942957,-0.6543414,115.530846,0.07148681,0.00029973223,1999.0,-418.8571608879349,-418.8571608879349,1.0
60000,1.8760403,-1.1052058,39.301025,0.067126855,0.00029966843,None,None,None,1.0
70000,1.9914699,-0.6117242,85.58901,0.07438538,0.00029961113,1999.0,-176.61804794452408,-176.61804794452408,1.0
80000,1.6490058,0.14599618,91.917015,0.06783736,0.00029955333,None,None,None,1.0
